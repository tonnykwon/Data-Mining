{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews =pd.read_table('reviews_sample.txt', header=None, sep='\\n')\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting minimum support\n",
    "# count on each transaction\n",
    "sup = 0.01\n",
    "min_sup = int(reviews.shape[0]*sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split as list\n",
    "review_list = reviews[0].map(lambda review: review.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length 1 pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "db = defaultdict(list)\n",
    "\n",
    "for sid, reviews in enumerate(review_list):\n",
    "    for eid, review in enumerate(reviews):\n",
    "        db[review].append([sid,eid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22104"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1085"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(list(zip(*db.get('year')))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db1 = defaultdict(pd.DataFrame)\n",
    "for key, items in db.items():\n",
    "    # compute support of items\n",
    "    support = len(np.unique(list(zip(*items))[0]))\n",
    "    if support >= min_sup:\n",
    "        db1[key] = pd.concat([db1[key], pd.DataFrame(items, columns=['sid','eid' ])], axis=1).set_index('sid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save length 1(93/100)\n",
    "with open('patterns.txt', 'w') as file:\n",
    "    for key, value in db1.items():\n",
    "        support = len(np.unique(value.index))\n",
    "        file.write(str(support)+\":\"+str(key)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length 2 patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate whether other item is adjacent\n",
    "def close(data, column1, column2):\n",
    "    diff = np.absolute(data[column1]-data[column2])\n",
    "    cond1 = diff<2\n",
    "    cond2 = diff>0\n",
    "    return data[cond1 & cond2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 23min (without index)\n",
    "# 21min (with index)\n",
    "\n",
    "db2 = defaultdict(pd.DataFrame)\n",
    "# copy db1\n",
    "db1copy = db1.copy()\n",
    "\n",
    "for key1, items1 in db1.items():\n",
    "    for key2, items2 in db1copy.items():\n",
    "\n",
    "        # merge based on key sid\n",
    "        temp = items1.merge(items2, left_index=True, right_index=True, how='inner', suffixes=('_x', '_y'))\n",
    "        \n",
    "        # all rows smaller than minimum\n",
    "        if temp.shape[0]<min_sup:\n",
    "            pass\n",
    "        \n",
    "        # see if contigious\n",
    "        temp = close(temp, 'eid_x', 'eid_y')\n",
    "        \n",
    "        # support check\n",
    "        support = len(np.unique(temp.index))\n",
    "        if support>= min_sup:\n",
    "            db2[key1+\";\"+key2] = temp\n",
    "            \n",
    "    # remove key from copy db\n",
    "    db1copy.pop(key1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide length 2\n",
    "db2split = defaultdict()\n",
    "for key, items in db2.items():\n",
    "    \n",
    "    # items where first key comes first\n",
    "    idx = items['eid_x']<items['eid_y']\n",
    "    # case when x comes first\n",
    "    support = len(np.unique(items[idx].index))\n",
    "    if support >= min_sup:\n",
    "        db2split[key] = items[idx]\n",
    "    \n",
    "    # case when y comes first\n",
    "    support = len(np.unique(items[~idx].index))\n",
    "    if support>= min_sup:\n",
    "        keys = key.split(';')\n",
    "        items.columns = ['eid_y', 'eid_x']\n",
    "        db2split[keys[1]+';'+keys[0]] = items[~idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length 3 Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 71.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# length 3 db\n",
    "db3 = defaultdict(pd.DataFrame)\n",
    "\n",
    "for key1, items1 in db2split.items():\n",
    "    for key2, items2 in db2split.items():\n",
    "        # compare key1 first and key2 last\n",
    "        key1last = key1.split(';')[1]\n",
    "        key2first = key2.split(';')[0]\n",
    "        key2last = key2.split(';')[1]\n",
    "        \n",
    "        # combine if keys are same\n",
    "        if key1last==key2first:\n",
    "            temp = items1.merge(items2, left_index=True, right_index=True, how='inner')\n",
    "            # minimum support check\n",
    "            support = len(np.unique(temp.index))\n",
    "            if temp.shape[0] >=min_sup:\n",
    "                db3[key1+\" \"+key2last] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "977 Length-1 <br>\n",
    "63 Length-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "print(len(db1.keys()))\n",
    "print(len(db2split.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all dbs\n",
    "results = db1.copy()\n",
    "results.update(db2split)\n",
    "# results.update(db3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"patterns.txt\", 'w') as file:\n",
    "    # length 1\n",
    "    for key, items in results.items():\n",
    "        support = len(np.unique(items.index))\n",
    "        file.write(str(support)+\":\"+';'.join(key.split())+ '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'one sees clearly only with the heart anything essential is invisible to the eyes'\n",
    "b = 'let my soul smile through my heart and my heart smile through my eyes that I may scatter rich smiles in sad hearts'\n",
    "\n",
    "a = a.split()\n",
    "b = b.split()\n",
    "\n",
    "unique_set = set(a).union(set(b))\n",
    "matA = pd.DataFrame(None, index = unique_set).T\n",
    "matB = pd.DataFrame(None, index = unique_set).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matA.loc[0,:]=0\n",
    "matB.loc[0,:]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, column in enumerate(matA):\n",
    "    for element in a:\n",
    "        if element==column:\n",
    "            matA.loc[0,column]+=1\n",
    "            \n",
    "for idx, column in enumerate(matB):\n",
    "    for element in b:\n",
    "        if element==column:\n",
    "            matB.loc[0,column]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(matA, matB.T)/(np.linalg.norm(matA)*np.linalg.norm(matB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= [[6.9, 3.1],\n",
    "[6.7,3.1],\n",
    "[6.9,3.1],\n",
    "[5.8,2.7],\n",
    "[6.8,3.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(list(zip(*x))[0])\n",
    "x2 = np.array(list(zip(*x))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x1, x2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
