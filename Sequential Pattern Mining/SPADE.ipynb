{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews =pd.read_table('reviews_sample.txt', header=None, sep='\\n')\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting minimum support\n",
    "# count on each transaction\n",
    "sup = 0.01\n",
    "min_sup = int(reviews.shape[0]*sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split as list\n",
    "review_list = reviews[0].map(lambda review: review.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length 1 pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "db = defaultdict(list)\n",
    "\n",
    "for sid, reviews in enumerate(review_list):\n",
    "    for eid, review in enumerate(reviews):\n",
    "        db[review].append([sid,eid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = defaultdict(pd.DataFrame)\n",
    "for key, items in db.items():\n",
    "    # compute support of items\n",
    "    support = len(np.unique(list(zip(*items))[0]))\n",
    "    if support > min_sup:\n",
    "        db1[key] = pd.concat([db1[key], pd.DataFrame(items, columns=['sid','eid' ])], axis=1).set_index('sid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length 2 patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate whether other item is adjacent\n",
    "def close(data, column1, column2):\n",
    "    diff = np.absolute(data[column1]-data[column2])\n",
    "    cond1 = diff<2\n",
    "    cond2 = diff>0\n",
    "    return data[cond1 & cond2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 23min (without index)\n",
    "# 23min (with index)\n",
    "\n",
    "db2 = defaultdict(pd.DataFrame)\n",
    "# copy db1\n",
    "db1copy = db1.copy()\n",
    "\n",
    "for key1, items1 in db1.items():\n",
    "    for key2, items2 in db1copy.items():\n",
    "        \n",
    "        # merge based on key sid\n",
    "        temp = items1.merge(items2, left_index=True, right_index=True, how='inner')\n",
    "        # see if contigious\n",
    "        temp = close(temp, 'eid_x', 'eid_y')\n",
    "        \n",
    "        # support check\n",
    "        support = len(np.unique(temp.index))\n",
    "        if support> min_sup:\n",
    "            db2[key1+\";\"+key2] = temp\n",
    "            \n",
    "    # remove key from copy db\n",
    "    db1copy.pop(key1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['like;place', 'like;really', 'like;would', 'like;look', 'like;looked', 'like;feel', 'like;felt', 'like;tasted', 'year;ago', 'selection;beer', 'food;good', 'food;service', 'food;great', 'food;whole', 'food;quality', 'best;one', 'cooked;perfectly', 'good;service', 'good;place', 'good;also', 'good;really', 'good;thing', 'good;pretty', 'good;price', 'good;get', 'customer;service', 'service;great', 'service;friendly', 'great;place', 'great;price', 'place;pittsburgh', 'place;love', 'place;get', 'place;one', 'staff;friendly', 'staff;wait', 'make;sure', 'ice;cream', 'really;nice', 'thing;one', 'night;last', 'night;saturday', 'pittsburgh;restaurant', 'would;definitely', 'would;recommend', 'time;first', 'time;last', 'time;every', 'time;long', 'time;next', 'better;much', 'definitely;back', 'come;back', 'pretty;much', 'lot;parking', 'hot;dog', 'fish;sandwich', 'fry;french', 'highly;recommend', 'price;reasonable', 'going;back', 'hour;happy', 'even;though', 'strip;district', 'across;street', 'one;favorite', 'back;coming', 'store;grocery', 'giant;eagle', 'reasonably;priced', 'pasta;trio'])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide length 2\n",
    "db2split = defaultdict()\n",
    "for key, items in db2.items():\n",
    "    \n",
    "    # items where first key comes first\n",
    "    idx = items['eid_x']<items['eid_y']\n",
    "    # case when x comes first\n",
    "    support = len(np.unique(items[idx].index))\n",
    "    if support > min_sup:\n",
    "        db2split[key] = items[idx]\n",
    "    \n",
    "    # case when y comes first\n",
    "    support = len(np.unique(items[~idx].index))\n",
    "    if support> min_sup:\n",
    "        keys = key.split(';')\n",
    "        db2split[keys[1]+';'+keys[0]] = items[~idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length 3 Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 76.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# length 3 db\n",
    "db3 = defaultdict(pd.DataFrame)\n",
    "\n",
    "for key1, items1 in db2split.items():\n",
    "    for key2, items2 in db2split.items():\n",
    "        # compare key1 first and key2 last\n",
    "        key1last = key1.split(';')[1]\n",
    "        key2first = key2.split(';')[0]\n",
    "        key2last = key2.split(';')[1]\n",
    "        \n",
    "        # combine if keys are same\n",
    "        if key1last==key2first:\n",
    "            temp = items1.merge(items2, left_index=True, right_index=True, how='inner')\n",
    "            # minimum support check\n",
    "            support = len(np.unique(temp.index))\n",
    "            if temp.shape[0] >min_sup:\n",
    "                db3[key1+\" \"+key2last] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all dbs\n",
    "results = db1.copy()\n",
    "results.update(db2)\n",
    "results.update(db3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"patterns.txt\", 'w') as file:\n",
    "    # length 1\n",
    "    for key, items in db1.items():\n",
    "        support = items.shape[0]\n",
    "        file.write(str(support)+\":\"+';'.join(key.split())+ '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'one sees clearly only with the heart anything essential is invisible to the eyes'\n",
    "b = 'let my soul smile through my heart and my heart smile through my eyes that I may scatter rich smiles in sad hearts'\n",
    "\n",
    "a = a.split()\n",
    "b = b.split()\n",
    "\n",
    "unique_set = set(a).union(set(b))\n",
    "matA = pd.DataFrame(None, index = unique_set).T\n",
    "matB = pd.DataFrame(None, index = unique_set).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "matA.loc[0,:]=0\n",
    "matB.loc[0,:]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, column in enumerate(matA):\n",
    "    for element in a:\n",
    "        if element==column:\n",
    "            matA.loc[0,column]+=1\n",
    "            \n",
    "for idx, column in enumerate(matB):\n",
    "    for element in b:\n",
    "        if element==column:\n",
    "            matB.loc[0,column]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11713032]])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(matA, matB.T)/(np.linalg.norm(matA)*np.linalg.norm(matB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= [[6.9, 3.1],\n",
    "[6.7,3.1],\n",
    "[6.9,3.1],\n",
    "[5.8,2.7],\n",
    "[6.8,3.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(list(zip(*x))[0])\n",
    "x2 = np.array(list(zip(*x))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.95256461],\n",
       "       [0.95256461, 1.        ]])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(x1, x2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
