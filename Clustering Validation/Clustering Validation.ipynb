{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = glob.glob('data/cluster*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read partition data\n",
    "partitions = pd.read_table('data/partitions.txt', sep =' ', header=None, index_col=0)\n",
    "partitions.columns = ['partition']\n",
    "\n",
    "# read clustering and partitions data\n",
    "data_list = []\n",
    "for path in path_list:\n",
    "    clustering = pd.read_table(path, sep=' ', header=None, index_col=0)\n",
    "    clustering.columns = ['cluster']\n",
    "    \n",
    "    # merge partition and clustering\n",
    "    data = partitions.merge(clustering, left_index=True, right_index=True)\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_nmi(data):\n",
    "    n = data.shape[0]\n",
    "    \n",
    "    # create partition x cluster prob matrix\n",
    "    unique_partition = np.unique(data.partition)\n",
    "    unique_cluster = np.unique(data.cluster)\n",
    "\n",
    "    pij = np.zeros([len(unique_partition), len(unique_cluster)])\n",
    "    \n",
    "    # calculate pij for each cluster\n",
    "    pij_pd = (data.groupby(['cluster','partition']).size().to_frame('count')/n).reset_index() #.reset_index()\n",
    "\n",
    "    # the probability of getting cluter i: #ni/n\n",
    "    pci = data.groupby('cluster').count()/n\n",
    "\n",
    "    # the probability of getting partition j : #nj/n\n",
    "    ptj = data.groupby('partition').count()/n\n",
    "    \n",
    "    # fill prob matrix\n",
    "    for partition in unique_partition:\n",
    "        for cluster in unique_cluster:\n",
    "            count = pij_pd.iloc[np.where((pij_pd.partition==partition) & (pij_pd.cluster==cluster))]['count']\n",
    "            if len(count)>0:\n",
    "                pij[partition, cluster] = count\n",
    "\n",
    "    # fill zero with smallest value\n",
    "    pij[np.where(pij==0)]=1e-7\n",
    "    \n",
    "    # calculate mi, H(T), H(C)\n",
    "    # pij * log(pij/ pci* ptj)\n",
    "    mi = np.sum(pij*np.log2(np.divide(pij ,np.dot(pci, ptj.T).T)))\n",
    "    HC = -np.sum(pci*np.log2(pci))\n",
    "    HT = -np.sum(ptj*np.log2(ptj))\n",
    "\n",
    "    nmi = mi/np.sqrt(HT[0] *HC[0])\n",
    "    \n",
    "    return nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmi =[cal_nmi(data) for data in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_jac(data):\n",
    "    from scipy.special import comb\n",
    "    \n",
    "    # cal counts of each group\n",
    "    nij = data.groupby(['cluster', 'partition']).size().to_frame()\n",
    "    ni = data.groupby('cluster').count()\n",
    "    mj = data.groupby('partition').count()\n",
    "    n = np.sum(np.sum(data))\n",
    "\n",
    "    # calculate pairs\n",
    "    N = np.sum(comb(n,2))\n",
    "    TP = np.sum(comb(nij, 2))\n",
    "    FN = np.sum(comb(mj, 2))-TP\n",
    "    FP = np.sum(comb(ni, 2))-TP\n",
    "    TN = N-(TP+FN+FP)\n",
    "\n",
    "    jaccard = TP/(TP+FN+FP)\n",
    "    \n",
    "    return jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac =[cal_jac(data) for data in data_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('socres.txt', 'w')as fp:\n",
    "    [fp.write(str(nmi[idx])+ ' '+str(jac[idx])+'\\n') for idx, data in enumerate(data_list)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
