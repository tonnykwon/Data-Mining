{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read train data\n",
    "data = pd.read_table('training.txt', sep=' ', header=None)\n",
    "# name label\n",
    "data.rename(columns={0:'label'}, inplace=True)\n",
    "# sepearte labels\n",
    "label = data.iloc[:, 0]\n",
    "\n",
    "# remove index: from data\n",
    "data = data.iloc[:, 1:].applymap(lambda x: x[x.find(':')+1:])\n",
    "data = data.astype(int)\n",
    "\n",
    "# rename columns and merge label\n",
    "data.columns = list(range(data.shape[1]))\n",
    "data = data.join(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read test data\n",
    "test = pd.read_table('testing.txt', sep=' ', header=None)\n",
    "\n",
    "# remove index: from data\n",
    "test = test.applymap(lambda x: x[x.find(':')+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "n = data.shape[0]\n",
    "idx = np.random.randint(0, n, int(n/20))\n",
    "val_data = data.iloc[idx,:]\n",
    "train_data = data.drop(idx)\n",
    "\n",
    "# data indexing\n",
    "train_data.index = range(0, train_data.shape[0])\n",
    "val_data.index = range(0, val_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gini(data):\n",
    "    _, counts = np.unique(np.array(data.label), return_counts= True)\n",
    "    \n",
    "    return 1-np.sum(np.square(counts/data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, column, feature):\n",
    "    \n",
    "    left = data[column][data[column]==feature].index.values\n",
    "    right = data[column][data[column]!=feature].index.values\n",
    "    \n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(data):\n",
    "    label_count = data.groupby('label').label.count()\n",
    "    \n",
    "    return label_count.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data, min_leaf):\n",
    "    gini_list = []\n",
    "    # loop over columns except labels\n",
    "    for column in data.iloc[:, :-1]:\n",
    "        for feature in np.unique(data[column]):\n",
    "            left_idx, right_idx = data_split(data, column, feature)\n",
    "\n",
    "            # check if splits are smaller than min_leaf\n",
    "            left_n = len(left_idx)\n",
    "            right_n = len(right_idx)\n",
    "            if left_n <= min_leaf and right_n <= min_leaf:\n",
    "                pass\n",
    "            elif left_n > min_leaf and right_n > min_leaf:\n",
    "                left_ratio = left_n/n\n",
    "                right_ratio = right_n/n\n",
    "                gini = left_ratio*get_gini(data.loc[left_idx])+right_ratio*get_gini(data.loc[right_idx])\n",
    "                gini_list.append((column, feature, gini))\n",
    "    \n",
    "    return min(gini_list, key= lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(72, 1): {(56, 3): {(82, 1): {(15, 3): None}}}}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = 5\n",
    "build_tree(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data, depth, tree=None):\n",
    "    n = data.shape[0]\n",
    "    if depth ==0 or n <= min_node:\n",
    "        pass\n",
    "    else:\n",
    "        # loop over columns except labels\n",
    "        column, feature, min_gini = find_best_split(data, min_leaf)\n",
    "        node = (column, feature)\n",
    "\n",
    "        # remove used column\n",
    "        left_idx, right_idx = data_split(data, column, feature)\n",
    "        data = data.drop(columns=column)\n",
    "\n",
    "        #Create an empty dictionary to create tree    \n",
    "        if tree is None:                    \n",
    "            tree={}\n",
    "            tree[node] = {}\n",
    "\n",
    "        # recursively buld\n",
    "        tree[node] = build_tree(data.loc[left_idx], depth-1, tree)\n",
    "        tree[node] = build_tree(data.loc[left_idx], depth-1, tree)\n",
    "        \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 1, 1)\n",
      "(56, 3, 2)\n",
      "(64, 1, 2)\n",
      "(123, 3, 3)\n",
      "(42, 1, 3)\n",
      "(23, 3, 3)\n",
      "(127, 3, 3)\n",
      "(29, 2, 4)\n",
      "(84, 1, 4)\n",
      "(101, 1, 4)\n",
      "(19, 1, 4)\n",
      "(99, 3, 4)\n",
      "(76, 1, 4)\n",
      "(96, 3, 5)\n",
      "(44, 1, 5)\n",
      "(21, 3, 5)\n",
      "(98, 2, 5)\n",
      "(8, 3, 5)\n",
      "(33, 1, 5)\n",
      "(14, 3, 6)\n",
      "(0, 3, 6)\n",
      "(68, 2, 6)\n",
      "(97, 3, 6)\n",
      "(49, 2, 6)\n",
      "(46, 1, 6)\n",
      "(27, 3, 6)\n",
      "(93, 3, 6)\n",
      "(102, 3, 7)\n",
      "(58, 3, 7)\n",
      "(59, 3, 7)\n",
      "(61, 1, 7)\n",
      "(34, 1, 7)\n",
      "(112, 3, 7)\n",
      "(126, 2, 7)\n",
      "(106, 3, 7)\n",
      "(57, 2, 7)\n",
      "(35, 1, 7)\n",
      "(1, 2, 8)\n",
      "(74, 2, 8)\n",
      "(69, 1, 8)\n",
      "(47, 3, 8)\n",
      "(20, 2, 8)\n",
      "(103, 1, 8)\n",
      "(28, 3, 8)\n",
      "(63, 1, 8)\n",
      "(48, 1, 8)\n",
      "(38, 3, 8)\n",
      "(2, 2, 9)\n",
      "(41, 3, 9)\n",
      "(45, 2, 9)\n",
      "(113, 1, 9)\n",
      "(60, 1, 9)\n",
      "(3, 2, 10)\n",
      "(18, 3, 10)\n",
      "(108, 2, 10)\n",
      "(87, 2, 10)\n",
      "(10, 3, 10)\n",
      "(4, 2, 11)\n",
      "(118, 1, 11)\n",
      "(91, 3, 11)\n",
      "(125, 1, 12)\n",
      "(105, 3, 12)\n",
      "(13, 1, 13)\n",
      "(5, 1, 13)\n",
      "(36, 3, 14)\n",
      "(6, 1, 15)\n",
      "Wall time: 58.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Build Tree\n",
    "max_depth = 20\n",
    "threshold = 1e-4\n",
    "min_node = 20\n",
    "min_leaf = 5\n",
    "\n",
    "# data copy\n",
    "data_copy = train_data.copy()\n",
    "\n",
    "## setup\n",
    "depth = 0\n",
    "result_list = []\n",
    "search_list = [(data_copy.index.values, depth)]\n",
    "base_gini_list = [get_gini(data_copy)]\n",
    "\n",
    "# breadth first search\n",
    "while search_list:\n",
    "    \n",
    "    node, depth = search_list.pop(0)\n",
    "    base_gini = base_gini_list.pop(0)\n",
    "    train = data_copy.loc[node]\n",
    "    gini_list = []\n",
    "    \n",
    "    # case used all columns\n",
    "    if train.shape[1] <=1:\n",
    "        break\n",
    "\n",
    "    n = len(node)\n",
    "    # case when depth is higher than max_depth\n",
    "    # case when node is too small to split\n",
    "    if depth >= max_depth or n <= min_node:\n",
    "        result_list.append((None, None, None))\n",
    "        continue\n",
    "\n",
    "    # loop over columns except labels\n",
    "    column, feature, min_gini = find_best_split(train, min_leaf)\n",
    "    \n",
    "    # check if satisfies threshold\n",
    "    if base_gini-min_gini < threshold:\n",
    "        result_list.append((None, None, None))\n",
    "        continue\n",
    "    \n",
    "    # remove used column\n",
    "    left_idx, right_idx = data_split(train, column, feature)\n",
    "    data_copy = data_copy.drop(columns=column)\n",
    "    \n",
    "    # append left and right node\n",
    "    depth +=1\n",
    "    result_list.append((column, feature, depth))\n",
    "    search_list.append((left_idx, depth))\n",
    "    search_list.append((right_idx, depth))\n",
    "    \n",
    "    # update base_gini and appends left, right base_gini\n",
    "    base_gini = min_gini\n",
    "    base_gini_list.append(base_gini)\n",
    "    base_gini_list.append(base_gini)\n",
    "    \n",
    "    print((column, feature, depth))\n",
    "    #print('left num: '+str(len(left_idx)))\n",
    "    #print('right num: '+str(len(right_idx)))\n",
    "    #print('new base gini: '+str(base_gini) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## predict\n",
    "# copy test set\n",
    "test_set = test.copy()\n",
    "train_set = data.copy()\n",
    "\n",
    "# setup\n",
    "split_list = result_list.copy()\n",
    "train_set['predict'] = None\n",
    "test_set['predict'] = None\n",
    "train_list = [train_set.index]\n",
    "test_list = [test_set.index]\n",
    "\n",
    "while split_list:\n",
    "    # get split criteria and datasets from each\n",
    "    column, feature, depth = split_list.pop(0)\n",
    "    \n",
    "    #print(str(column)+' '+str(feature)+', '+str(depth))\n",
    "    train_idx = train_list.pop(0)\n",
    "    test_idx = test_list.pop(0)\n",
    "    train = train_set.loc[train_idx]\n",
    "    test = test_set.loc[test_idx]\n",
    "    \n",
    "    # certain condition not met\n",
    "    if column is None:\n",
    "        continue\n",
    "    \n",
    "    n = len(train_idx)\n",
    "    if n <= min_node:\n",
    "        continue\n",
    "    \n",
    "    train_left_idx, train_right_idx = data_split(train, column, feature)\n",
    "    test_left_idx, test_right_idx = data_split(test, column, feature)\n",
    "    \n",
    "    # set label\n",
    "    left_label = get_label(train_set.loc[train_left_idx])\n",
    "    right_label = get_label(train_set.loc[train_right_idx])\n",
    "    # test set labels\n",
    "    test_set.loc[test_left_idx, 'predict'] = left_label\n",
    "    test_set.loc[test_right_idx, 'predict'] = right_label\n",
    "    # train set labels\n",
    "    train_set.loc[train_left_idx, 'predict'] = left_label\n",
    "    train_set.loc[train_right_idx, 'predict'] = right_label\n",
    "\n",
    "    # put on the list\n",
    "    # if len(train_left_idx) > min_leaf and len(train_right_idx) > min_leaf:\n",
    "    train_list.append(train_left_idx)\n",
    "    train_list.append(train_right_idx)\n",
    "    test_list.append(test_left_idx)\n",
    "    test_list.append(test_right_idx)\n",
    "    # print('left label: '+str(left_label))\n",
    "    # print('left num: '+str(len(train_left_idx)))\n",
    "    # print('right label: '+str(right_label))\n",
    "    # print('right num: '+str(len(train_right_idx)) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 2, 3, 4], dtype=int64), array([702, 721, 727, 706], dtype=int64))\n",
      "(array([1], dtype=object), array([1000], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_data.label, return_counts=True))\n",
    "print(np.unique(test_set.predict, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37333333333333335"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_set.label == test_set.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {'max_depth':[10, 20, 30], 'min_samples_split': [2, 5, 10, 30],\n",
    "              'min_samples_leaf':[3, 5, 10], 'min_impurity_decrease':[1e-3, 1e-4]}\n",
    "dt = DecisionTreeClassifier()\n",
    "grid_dt = GridSearchCV(dt, parameters, cv=5)\n",
    "grid_dt.fit(train_data.iloc[:,:-1], train_data.label)\n",
    "\n",
    "print(grid_dt.best_estimator_)\n",
    "print(grid_dt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7038205397826849"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=30,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "dt.fit(train_data.iloc[:,:-1], train_data.label)\n",
    "pred = dt.predict(train_data.iloc[:,:-1])\n",
    "np.mean(pred ==train_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.txt', 'w') as fp:\n",
    "    [fp.write(str(predict)+'\\n') for predict in pred]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
